{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c2d134-3db8-4a94-a694-fd51ef3fc2d3",
   "metadata": {},
   "source": [
    "# E001: Visualization of Tree-Ring Watermark's Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbee98cf",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Relative imports\n",
    "from tree_ring import *\n",
    "from utils import *\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Experiment parameters\n",
    "image_size = 64\n",
    "labels = [0]\n",
    "tree_ring_paras = dict(\n",
    "    w_channel=2,\n",
    "    w_pattern=\"ring\",\n",
    "    w_mask_shape=\"circle\",\n",
    "    w_radius=10,\n",
    "    w_measurement=\"l1_complex\",\n",
    "    w_injection=\"complex\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ddd6db6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=3, alpha_prev=0.9943352937698364, alpha_next=0.9886365532875061, a=-0.5132330656051636, b=-0.6949071884155273, in=-0.5843853950500488, out=-0.5640789866447449\n",
      "t=2, alpha_prev=0.9981142282485962, alpha_next=0.9943352937698364, a=-0.519475519657135, b=-0.6122012138366699, in=-0.5640789866447449, out=-0.5455706119537354\n",
      "t=1, alpha_prev=0.9999586939811707, alpha_next=0.9981142282485962, a=-0.525180459022522, b=-0.4809526801109314, in=-0.5455706119537354, out=-0.5282607078552246\n",
      "t=0, alpha_prev=1.0, alpha_next=0.9999586939811707, a=-0.5274044275283813, b=-0.13496221601963043, in=-0.5282607078552246, out=-0.5274044275283813\n",
      "t=0, alpha_prev=None, alpha_next=0.9981142282485962, a=-0.5272672772407532, b=-0.023033279925584793, in=-0.5274044275283813, out=-0.5277701020240784\n",
      "t=1, alpha_prev=None, alpha_next=0.9943352937698364, a=-0.5061648488044739, b=-0.5085208415985107, in=-0.5277701020240784, out=-0.5430026650428772\n",
      "t=2, alpha_prev=None, alpha_next=0.9886365532875061, a=-0.5016630291938782, b=-0.5681648254394531, in=-0.5430026650428772, out=-0.5593706369400024\n",
      "t=3, alpha_prev=None, alpha_next=0.9810401797294617, a=-0.49886396527290344, b=-0.5942731499671936, in=-0.5593706369400024, out=-0.5759403705596924\n",
      "Maximum Absolute Difference: 1.460119366645813\n",
      "Maximum Relative Difference: 1364.8115234375\n"
     ]
    }
   ],
   "source": [
    "# TODO: Debug, reverse diffusion does not go back to the initial latent!!!\n",
    "\n",
    "# Load guided diffusion models which are class-conditional diffusion models trained on ImageNet\n",
    "model, diffusion = load_guided_diffusion_model(image_size, device)\n",
    "\n",
    "\n",
    "# Generate images without watermark\n",
    "images_wo = guided_diffusion_without_watermark(\n",
    "    model, diffusion, labels, image_size, diffusion_seed=0\n",
    ")\n",
    "\n",
    "# Reverse diffusion on images with and without watermark\n",
    "reversed_latents_wo = reverse_guided_diffusion(\n",
    "    model,\n",
    "    diffusion,\n",
    "    images=images_wo,\n",
    "    image_size=image_size,\n",
    "    # For sanity check purpose, remove later\n",
    "    default_labels=labels,\n",
    ")\n",
    "\n",
    "set_random_seed(0)\n",
    "shape = (len(labels), 3, image_size, image_size)\n",
    "init_latents_wo = torch.randn(*shape, device=device)\n",
    "# Calculate absolute differences\n",
    "abs_diff = torch.abs(reversed_latents_wo - init_latents_wo)\n",
    "\n",
    "# Calculate relative differences. We add a small constant in the denominator to prevent division by zero.\n",
    "epsilon = 1e-10\n",
    "rel_diff = abs_diff / (torch.abs(init_latents_wo) + epsilon)\n",
    "\n",
    "# Get maximum absolute and relative differences\n",
    "max_abs_diff = torch.max(abs_diff)\n",
    "max_rel_diff = torch.max(rel_diff)\n",
    "\n",
    "print(f\"Maximum Absolute Difference: {max_abs_diff.item()}\")\n",
    "print(f\"Maximum Relative Difference: {max_rel_diff.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32240a",
   "metadata": {},
   "source": [
    "## Implement Tree-Ring Watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load guided diffusion models which are class-conditional diffusion models trained on ImageNet\n",
    "model, diffusion = load_guided_diffusion_model(image_size, device)\n",
    "\n",
    "\n",
    "# Generate images without watermark\n",
    "images_wo = guided_diffusion_without_watermark(\n",
    "    model, diffusion, labels, image_size, diffusion_seed=0\n",
    ")\n",
    "\n",
    "# Generate one watermark message (which is the key in tree-ring's paper)\n",
    "message = generate_message(\n",
    "    message_seed=0,\n",
    "    image_size=image_size,\n",
    "    tree_ring_paras=tree_ring_paras,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Generate one watermark key (which is the mask in tree-ring's paper)\n",
    "key = generate_key(\n",
    "    key_seed=0, image_size=image_size, tree_ring_paras=tree_ring_paras, device=device\n",
    ")\n",
    "\n",
    "# Generate images with watermark\n",
    "images_w = guided_diffusion_with_watermark(\n",
    "    model,\n",
    "    diffusion,\n",
    "    labels,\n",
    "    keys=key,\n",
    "    messages=message,\n",
    "    tree_ring_paras=tree_ring_paras,\n",
    "    image_size=image_size,\n",
    "    diffusion_seed=0,\n",
    ")\n",
    "\n",
    "# Reverse diffusion on images with and without watermark\n",
    "reversed_latents_wo = reverse_guided_diffusion(\n",
    "    model,\n",
    "    diffusion,\n",
    "    images=images_wo,\n",
    "    image_size=image_size,\n",
    ")\n",
    "reversed_latents_w = reverse_guided_diffusion(\n",
    "    model,\n",
    "    diffusion,\n",
    "    images=images_w,\n",
    "    image_size=image_size,\n",
    ")\n",
    "\n",
    "# Detect and evaluate watermark\n",
    "auc, acc, low = detect_evaluate_watermark(\n",
    "    reversed_latents_wo,\n",
    "    reversed_latents_w,\n",
    "    keys=key,\n",
    "    messages=message,\n",
    "    tree_ring_paras=tree_ring_paras,\n",
    "    image_size=image_size,\n",
    ")\n",
    "print(\n",
    "    f\"Sanity check when there is no attack: AUC={auc}, accuracy={acc}, and TPR@1%FPR={low}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dc1d6",
   "metadata": {},
   "source": [
    "## How Tree-Ring Watermarks are Changing through Forward Diffusion Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca344df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get iterators for guided diffusion with and without watermark\n",
    "images_prog_wo = guided_diffusion_without_watermark(\n",
    "    model,\n",
    "    diffusion,\n",
    "    labels,\n",
    "    image_size=image_size,\n",
    "    diffusion_seed=0,\n",
    "    progressive=True,\n",
    "    return_image=True,\n",
    ")\n",
    "images_prog_w = guided_diffusion_with_watermark(\n",
    "    model,\n",
    "    diffusion,\n",
    "    labels,\n",
    "    keys=key,\n",
    "    messages=message,\n",
    "    tree_ring_paras=tree_ring_paras,\n",
    "    image_size=image_size,\n",
    "    diffusion_seed=0,\n",
    "    progressive=True,\n",
    "    return_image=True,\n",
    ")\n",
    "\n",
    "# Guided diffusion with and without watermark together step by step\n",
    "figs = []\n",
    "for images_wo, images_w in zip(images_prog_wo, images_prog_w):\n",
    "    # Unnormalize images\n",
    "    images_wo_tensor = to_tensor_and_normalize(images_wo)\n",
    "    images_w_tensor = to_tensor_and_normalize(images_w)\n",
    "    # Pixel-wise delta between images with and without watermark\n",
    "    pixel_delta = torch.abs(images_wo_tensor - images_w_tensor)\n",
    "    # FFT delta between images with and without watermark\n",
    "    fft_delta = torch.abs(\n",
    "        torch.fft.fftshift(\n",
    "            torch.fft.fft2(images_wo_tensor - images_w_tensor),\n",
    "            dim=(-1, -2),\n",
    "        )\n",
    "    )\n",
    "    figs.append(\n",
    "        visualize_image_grid(\n",
    "            [\n",
    "                images_wo,\n",
    "                images_w,\n",
    "                unnormalize_and_to_pil(pixel_delta * 10),\n",
    "                unnormalize_and_to_pil(fft_delta / fft_delta.max()),\n",
    "            ],\n",
    "            col_headers=[\n",
    "                \"w/o watermark\",\n",
    "                \"w/ watermark\",\n",
    "                \"pixel-delta * 10\",\n",
    "                \"fft-delta (max-normd)\",\n",
    "            ],\n",
    "            row_headers=get_imagenet_class_names(labels),\n",
    "            fontsize=10,\n",
    "            column_first=True,\n",
    "        )\n",
    "    )\n",
    "    plt.show(figs[-1])\n",
    "\n",
    "# Make gif from the figures\n",
    "make_gif(figs, filepath=\"./results/E001/forward_diffusion.gif\")\n",
    "\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f656a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the evolution of tree-ring watermark through diffusion\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "\n",
    "def paired_transforms(img1, img2, img3, type=None, index=None):\n",
    "    # Ensure img1 and img2 are PIL Images\n",
    "    assert type in [\"Rotation\", \"RandomResizedCrop\", \"RandomErasing\", \"IndexedErasing\"]\n",
    "\n",
    "    if type == \"Rotation\":\n",
    "        # Rotation\n",
    "        angle = random.uniform(-30, 30)  # Random rotation by up to 30 degrees\n",
    "        img1 = F.rotate(img1, angle)\n",
    "        img2 = F.rotate(img2, angle)\n",
    "    elif type == \"RandomResizedCrop\":\n",
    "        # Random Resized Crop\n",
    "        i, j, h, w = transforms.RandomResizedCrop.get_params(\n",
    "            img1, scale=(0.08, 1.0), ratio=(3 / 4, 4 / 3)\n",
    "        )\n",
    "        img1 = F.resized_crop(img1, i, j, h, w, (64, 64))\n",
    "        img2 = F.resized_crop(img2, i, j, h, w, (64, 64))\n",
    "    elif type == \"RandomErasing\":\n",
    "        # Cutout\n",
    "        x, y = random.randint(0, img1.width), random.randint(0, img1.height)\n",
    "        h, w = random.randint(\n",
    "            int(0.02 * img1.width), int(0.33 * img1.width)\n",
    "        ), random.randint(int(0.02 * img1.height), int(0.33 * img1.height))\n",
    "        img1, img2 = transforms.ToTensor()(img1), transforms.ToTensor()(img2)\n",
    "        img1 = F.erase(img1, x, y, h, w, v=0)\n",
    "        img2 = F.erase(img2, x, y, h, w, v=0)\n",
    "        img1, img2 = transforms.ToPILImage()(img1), transforms.ToPILImage()(img2)\n",
    "    elif type == \"IndexedErasing\":\n",
    "        assert index >= 0 and index <= 8 * 8\n",
    "        # Cutout\n",
    "        x, y = 8 * (index // 8), 8 * (index % 8)\n",
    "        h, w = 16, 16\n",
    "        img1, img2, img3 = (\n",
    "            transforms.ToTensor()(img1),\n",
    "            transforms.ToTensor()(img2),\n",
    "            transforms.ToTensor()(img3),\n",
    "        )\n",
    "        img1 = F.erase(img1, x, y, h, w, v=0)\n",
    "        img2 = F.erase(img2, x, y, h, w, v=0)\n",
    "        img3 = F.erase(img3, x, y, h, w, v=0)\n",
    "        img1, img2, img3 = (\n",
    "            transforms.ToPILImage()(img1),\n",
    "            transforms.ToPILImage()(img2),\n",
    "            transforms.ToPILImage()(img3),\n",
    "        )\n",
    "    return img1, img2, img3\n",
    "\n",
    "\n",
    "def generate_and_compare_reverse(\n",
    "    model,\n",
    "    diffusion,\n",
    "    prompt,\n",
    "    key,\n",
    "    image_size,\n",
    "    tree_ring_paras,\n",
    "    init_latents_w,\n",
    "    watermarking_mask,\n",
    "    diffusion_seed,\n",
    "):\n",
    "    set_random_seed(diffusion_seed)\n",
    "    # For this class-conditioned diffusion model, prompts are just class ids\n",
    "    assert isinstance(prompt, int) and 0 <= prompt < 1000\n",
    "    # For simplicity, fix batch size to one\n",
    "    shape = (1, 3, image_size, image_size)\n",
    "    tree_ring_args = namedtuple(\"Args\", tree_ring_paras.keys())(**tree_ring_paras)\n",
    "    # Unnormalize for\n",
    "    mean = [0.5, 0.5, 0.5]\n",
    "    std = [0.5, 0.5, 0.5]\n",
    "    unnormalize = transforms.Normalize(\n",
    "        (-mean[0] / std[0], -mean[1] / std[1], -mean[2] / std[2]),\n",
    "        (1 / std[0], 1 / std[1], 1 / std[2]),\n",
    "    )\n",
    "    # First pic\n",
    "    # Diffusion w/o watermark\n",
    "    no_wm_iter = diffusion.ddim_sample_loop_progressive(\n",
    "        model=model,\n",
    "        shape=shape,\n",
    "        noise=init_latents_w,\n",
    "        clip_denoised=True,\n",
    "        model_kwargs=dict(y=torch.tensor([prompt], device=device)),\n",
    "        device=device,\n",
    "    )\n",
    "    # Diffusion w watermark\n",
    "    wm_iter = diffusion.ddim_sample_loop_progressive(\n",
    "        model=model,\n",
    "        shape=shape,\n",
    "        noise=inject_watermark(init_latents_w, watermarking_mask, key, tree_ring_args),\n",
    "        clip_denoised=True,\n",
    "        model_kwargs=dict(y=torch.tensor([prompt], device=device)),\n",
    "        device=device,\n",
    "    )\n",
    "    # Main loop\n",
    "    image_list = []\n",
    "    for no_wm_sample, wm_sample in zip(no_wm_iter, wm_iter):\n",
    "        diff_init = (\n",
    "            torch.abs(\n",
    "                unnormalize(no_wm_sample[\"sample\"][0])\n",
    "                - unnormalize(wm_sample[\"sample\"][0])\n",
    "            )\n",
    "            * 10\n",
    "        )\n",
    "        break\n",
    "\n",
    "    # Diffusion\n",
    "    no_wm_output = diffusion.ddim_sample_loop(\n",
    "        model=model,\n",
    "        shape=shape,\n",
    "        noise=init_latents_w,\n",
    "        clip_denoised=True,\n",
    "        model_kwargs=dict(y=torch.tensor([prompt], device=device)),\n",
    "        device=device,\n",
    "        return_image=True,\n",
    "    )\n",
    "    wm_output = diffusion.ddim_sample_loop(\n",
    "        model=model,\n",
    "        shape=shape,\n",
    "        noise=inject_watermark(init_latents_w, watermarking_mask, key, tree_ring_args),\n",
    "        clip_denoised=True,\n",
    "        model_kwargs=dict(y=torch.tensor([prompt], device=device)),\n",
    "        device=device,\n",
    "        return_image=True,\n",
    "    )\n",
    "    no_wm_image, wm_image = no_wm_output[0], wm_output[0]\n",
    "    # no_wm_image = unnormalize(no_wm_image).permute(1, 2, 0).cpu()*255\n",
    "    # wm_image = unnormalize(wm_image).permute(1, 2, 0).cpu()*255\n",
    "\n",
    "    image_list = []\n",
    "    for index in trange(8 * 8):\n",
    "        # Augmentation\n",
    "        no_wm_image_aug, wm_image_aug, diff_init_aug = paired_transforms(\n",
    "            no_wm_image,\n",
    "            wm_image,\n",
    "            transforms.ToPILImage()(diff_init),\n",
    "            type=\"IndexedErasing\",\n",
    "            index=index,\n",
    "        )\n",
    "\n",
    "        # Reverse Diffusion w/o watermark\n",
    "        no_wm_iter_reverse = diffusion.ddim_reverse_sample_loop_progressive(\n",
    "            model=model,\n",
    "            shape=shape,\n",
    "            image=no_wm_image_aug,\n",
    "            clip_denoised=True,\n",
    "            model_kwargs=dict(y=torch.tensor([prompt], device=device)),\n",
    "            device=device,\n",
    "        )\n",
    "        # Reverse Diffusion w watermark\n",
    "        wm_iter_reverse = diffusion.ddim_reverse_sample_loop_progressive(\n",
    "            model=model,\n",
    "            shape=shape,\n",
    "            image=wm_image_aug,\n",
    "            clip_denoised=True,\n",
    "            model_kwargs=dict(y=torch.tensor([prompt], device=device)),\n",
    "            device=device,\n",
    "        )\n",
    "        # Main loop\n",
    "        for no_wm_sample_reverse, wm_sample_reverse in zip(\n",
    "            no_wm_iter_reverse, wm_iter_reverse\n",
    "        ):\n",
    "            no_wm_image_reverse, wm_image_reverse = (\n",
    "                no_wm_sample_reverse[\"sample\"][0],\n",
    "                wm_sample_reverse[\"sample\"][0],\n",
    "            )\n",
    "        # Plot\n",
    "        fft_diff = torch.abs(\n",
    "            torch.fft.fftshift(\n",
    "                torch.fft.fft2(\n",
    "                    unnormalize(no_wm_image_reverse) - unnormalize(wm_image_reverse)\n",
    "                )  # , dim=(-1, -2) check if this is making difference\n",
    "            )\n",
    "        )\n",
    "        fft_diff = fft_diff / fft_diff.max()\n",
    "        fig = visualize_images(\n",
    "            [\n",
    "                [\n",
    "                    transforms.ToTensor()(no_wm_image_aug),\n",
    "                    transforms.ToTensor()(wm_image_aug),\n",
    "                    transforms.ToTensor()(diff_init_aug),\n",
    "                    torch.abs(\n",
    "                        transforms.ToTensor()(no_wm_image_aug)\n",
    "                        - transforms.ToTensor()(wm_image_aug)\n",
    "                    )\n",
    "                    * 10,\n",
    "                    unnormalize(no_wm_image_reverse),\n",
    "                    unnormalize(wm_image_reverse),\n",
    "                    torch.abs(\n",
    "                        unnormalize(no_wm_image_reverse) - unnormalize(wm_image_reverse)\n",
    "                    )\n",
    "                    * 10,\n",
    "                    fft_diff,\n",
    "                ]\n",
    "            ],\n",
    "            [\n",
    "                \"w/o watermark\",\n",
    "                \"w/ watermark\",\n",
    "                \"delta*10 (inited)\",\n",
    "                \"delta*10\",\n",
    "                \"w/o watermark (reversed)\",\n",
    "                \"w/ watermark (reversed)\",\n",
    "                \"delta*10 (reversed)\",\n",
    "                \"fft-delta (reversed, normd)\",\n",
    "            ],\n",
    "            [\"\"],\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "        buf = BytesIO()  # in-memory binary stream\n",
    "        fig.savefig(\n",
    "            buf, format=\"png\", dpi=200, bbox_inches=\"tight\"\n",
    "        )  # save figure to the stream in PNG format\n",
    "        buf.seek(0)\n",
    "        image_list.append(imageio.imread(buf))  # read image from the stream\n",
    "        plt.show(fig)\n",
    "        plt.close(fig)\n",
    "    imageio.mimsave(\"vis_64x64_0_3.gif\", image_list, loop=1, duration=0.5)\n",
    "    return None\n",
    "\n",
    "\n",
    "set_random_seed(0)\n",
    "key = create_key(key_seed=0, image_size=image_size, tree_ring_paras=tree_ring_paras)\n",
    "shape = (1, 3, image_size, image_size)\n",
    "tree_ring_args = namedtuple(\"Args\", tree_ring_paras.keys())(**tree_ring_paras)\n",
    "init_latents_w = torch.randn(*shape, device=device)\n",
    "watermarking_mask = get_watermarking_mask(init_latents_w, tree_ring_args, device=device)\n",
    "generate_and_compare_reverse(\n",
    "    model,\n",
    "    diffusion,\n",
    "    0,\n",
    "    key,\n",
    "    image_size,\n",
    "    tree_ring_paras,\n",
    "    init_latents_w,\n",
    "    watermarking_mask,\n",
    "    3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

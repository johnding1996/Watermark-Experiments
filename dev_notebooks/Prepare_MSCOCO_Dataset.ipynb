{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from tqdm.auto import tqdm, trange\n",
    "from torchvision.datasets import CocoCaptions\n",
    "from torchvision.transforms import Compose, CenterCrop, Resize\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "from open_clip import get_tokenizer\n",
    "from metrics import (\n",
    "    load_perplexity_model_and_tokenizer,\n",
    "    compute_prompt_perplexity,\n",
    "    load_aesthetics_and_artifacts_models,\n",
    "    compute_aesthetics_and_artifacts_scores,\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "clip_tokenizer = get_tokenizer(\"ViT-g-14\")\n",
    "ppl_models = load_perplexity_model_and_tokenizer()\n",
    "aa_models = load_aesthetics_and_artifacts_models()\n",
    "\n",
    "\n",
    "# coco_dataset = CocoCaptions(\n",
    "#     root=\"/fs/nexus-projects/HuangWM/datasets/source/MSCOCO/val2017/\",\n",
    "#     annFile=\"/fs/nexus-projects/HuangWM/datasets/source/MSCOCO/annotations/captions_val2017.json\",\n",
    "# )\n",
    "\n",
    "\n",
    "# # Convert to HuggingFace Dataset\n",
    "# def gen():\n",
    "#     for i in trange(len(coco_dataset)):\n",
    "#         image = dataset[i][0]\n",
    "#         transform = Compose([CenterCrop(min(image.size)), Resize((512, 512))])\n",
    "#         prompt = dataset[i][1][0]\n",
    "#         # Only use the first caption\n",
    "#         yield {\"image\": transform(image), \"prompt\": prompt}\n",
    "\n",
    "\n",
    "# dataset = Dataset.from_generator(gen)\n",
    "# dataset.save_to_disk(\"/fs/nexus-projects/HuangWM/datasets/source/mscoco_5k\")\n",
    "\n",
    "dataset = load_from_disk(\"/fs/nexus-projects/HuangWM/datasets/source/mscoco_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and normalize prompts according to CLIP tokenizer\n",
    "# For MSCOCO, this does not filter out any data\n",
    "dataset = dataset.filter(\n",
    "    lambda data: 0 < len(clip_tokenizer.encode(data[\"prompt\"])) <= 75\n",
    ")\n",
    "normalized_prompts = []\n",
    "for prompt in tqdm(dataset[\"prompt\"]):\n",
    "    normalized_prompts.append(clip_tokenizer.decode(clip_tokenizer.encode(prompt)))\n",
    "dataset = dataset.add_column(\"normalized_prompt\", normalized_prompts)\n",
    "dataset = dataset.remove_columns([\"prompt\"])\n",
    "dataset = dataset.rename_column(\"normalized_prompt\", \"prompt\")\n",
    "\n",
    "# Add perplexity, aesthetic, and artifact scores\n",
    "ppls = []\n",
    "for prompt in tqdm(dataset[\"prompt\"]):\n",
    "    ppls.append(compute_prompt_perplexity(prompt, ppl_models))\n",
    "aesthetics = []\n",
    "artifacts = []\n",
    "for image in tqdm(dataset[\"image\"]):\n",
    "    aesthetic, artifact = compute_aesthetics_and_artifacts_scores(image, aa_models)\n",
    "    aesthetics.append(aesthetic)\n",
    "    artifacts.append(artifact)\n",
    "dataset = dataset.add_column(\"ppl\", ppls)\n",
    "dataset = dataset.add_column(\"aesthetic\", aesthetics)\n",
    "dataset = dataset.add_column(\"artifact\", artifacts)\n",
    "\n",
    "# Calculate the score for ranking\n",
    "# Curently, the score is defined as: aesthetic + (10 - artifact)\n",
    "# The perplexity is not included in the score because it is not a good indicator\n",
    "# For MSCOCO, this does change the final images used, since all 5k images are used\n",
    "key = np.array(dataset[\"aesthetic\"]) + (10 - np.array(dataset[\"artifact\"]))\n",
    "dataset_appended = dataset.add_column(\"key\", key)\n",
    "dataset = dataset_appended.sort(\"key\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the images and prompts as json\n",
    "selected_size = 5000\n",
    "prompt_dict = {}\n",
    "for i in trange(selected_size):\n",
    "    dataset[i][\"image\"].save(\n",
    "        f\"/fs/nexus-projects/HuangWM/datasets/main/mscoco/real/{i}.png\"\n",
    "    )\n",
    "    prompt_dict[str(i)] = dataset[i][\"prompt\"]\n",
    "with open(\n",
    "    \"/fs/nexus-projects/HuangWM/datasets/main/mscoco/prompts.json\",\n",
    "    \"w\",\n",
    ") as json_file:\n",
    "    json.dump(prompt_dict, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# Save the dataset to disk\n",
    "dataset.save_to_disk(\"/fs/nexus-projects/HuangWM/datasets/source/mscoco_5k_ranked\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

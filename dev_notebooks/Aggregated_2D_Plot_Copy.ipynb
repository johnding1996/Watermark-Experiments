{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "QUALITY_METRICS = {\n",
    "    \"legacy_fid\": \"FID\",\n",
    "    \"clip_fid\": \"CLIP FID\",\n",
    "    \"psnr\": \"PSNR\",\n",
    "    \"ssim\": \"SSIM\",\n",
    "    \"nmi\": \"Normed Mutual-Info\",\n",
    "    \"lpips\": \"LPIPS\",\n",
    "    \"watson\": \"Watson-DFT\",\n",
    "    \"aesthetics\": \"Delta Aesthetics\",\n",
    "    \"artifacts\": \"Delta Artifacts\",\n",
    "    \"clip_score\": \"Delta CLIP-Score\",\n",
    "}\n",
    "\n",
    "ATTACK_NAMES = {\n",
    "    \"distortion_single_rotation\": \"Dist-Rotation\",\n",
    "    \"distortion_single_resizedcrop\": \"Dist-RCrop\",\n",
    "    \"distortion_single_erasing\": \"Dist-Erase\",\n",
    "    \"distortion_single_brightness\": \"Dist-Bright\",\n",
    "    \"distortion_single_contrast\": \"Dist-Contrast\",\n",
    "    \"distortion_single_blurring\": \"Dist-Blur\",\n",
    "    \"distortion_single_noise\": \"Dist-Noise\",\n",
    "    \"distortion_single_jpeg\": \"Dist-JPEG\",\n",
    "    \"distortion_combo_geometric\": \"DistCom-Geo\",\n",
    "    \"distortion_combo_photometric\": \"DistCom-Photo\",\n",
    "    \"distortion_combo_degradation\": \"DistCom-Deg\",\n",
    "    \"distortion_combo_all\": \"DistCom-All\",\n",
    "    \"regen_diffusion\": \"Regen-Diff\",\n",
    "    \"regen_diffusion_prompt\": \"Regen-DiffP\",\n",
    "    \"regen_vae\": \"Regen-VAE\",\n",
    "    \"kl_vae\": \"Regen-KLVAE\",\n",
    "    \"2x_regen\": \"Rinse-2xDiff\",\n",
    "    \"4x_regen\": \"Rinse-4xDiff\",\n",
    "    \"4x_regen_bmshj\": \"RinseD-VAE\",\n",
    "    \"4x_regen_kl_vae\": \"RinseD-KLVAE\",\n",
    "    \"adv_emb_same_vae_untg\": \"AdvEmbG-KLVAE8\",\n",
    "    \"adv_emb_resnet18_untg\": \"AdvEmbB-RN18\",\n",
    "    \"adv_emb_clip_untg_alphaRatio_0.05_step_200\": \"AdvEmbB-CLIP\",\n",
    "    \"adv_emb_klf16_vae_untg\": \"AdvEmbB-KLVAE16\",\n",
    "    \"adv_emb_sdxl_vae_untg\": \"AdvEmbB-SdxlVAE\",\n",
    "    \"adv_cls_unwm_wm_0.01_50_warm_train3k\": \"AdvCls-UnWM&WM\",\n",
    "    \"adv_cls_real_wm_0.01_50_warm\": \"AdvCls-Real&WM\",\n",
    "    \"adv_cls_wm1_wm2_0.01_50_warm\": \"AdvCls-WM1&WM2\",\n",
    "}\n",
    "\n",
    "WATERMARK_METHODS = {\n",
    "    \"tree_ring\": \"Tree-Ring\",\n",
    "    \"stable_sig\": \"Stable-Signature\",\n",
    "    \"stegastamp\": \"Stega-Stamp\",\n",
    "}\n",
    "\n",
    "PERFORMANCE_METRICS = {\n",
    "    \"acc_1\": \"Mean Detection Accuracy\",\n",
    "    \"auc_1\": \"AUC\",\n",
    "    \"low100_1\": \"TPR@1%FPR\",\n",
    "    \"low1000_1\": \"TPR@0.1%FPR\",\n",
    "    \"acc_100\": \"Identification Accuracy (100 Users)\",\n",
    "    \"acc_1000\": \"Identification Accuracy (1K Users)\",\n",
    "    \"acc_1000000\": \"Identification Accuracy (1M Users)\",\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.read_pickle(\"all_result.pkl\")\n",
    "quality_threshold_low, quality_threshold_high = 0.1, 0.9\n",
    "\n",
    "# Change here\n",
    "#############################################\n",
    "performance_metric = \"acc_1000000\"  # \"low1000_1\"\n",
    "performance_threshold_low, performance_threshold_high = 0.4, 0.7  # 0.7, 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract qualities metircs of removal setup (and remove abnormal None values) as a dictionary of lists\n",
    "qualities = {\n",
    "    k: [\n",
    "        v[0] if k not in [\"psnr\", \"ssim\", \"nmi\", \"artifacts\"] else -v[0]\n",
    "        for v in df[df[\"eval_setup\"] == \"removal\"][k]\n",
    "        if v is not None\n",
    "    ]\n",
    "    for k in QUALITY_METRICS.keys()\n",
    "    if k not in [\"watson\", \"clip_score\"]\n",
    "}\n",
    "\n",
    "# Number of types (subplots)\n",
    "num_types = len(qualities)\n",
    "\n",
    "# Create a subplot figure with 1 row and `num_types` columns\n",
    "fig = make_subplots(rows=1, cols=num_types, shared_yaxes=True)\n",
    "\n",
    "# Loop through each item in the dictionary and add to subplots\n",
    "for i, (key, values) in enumerate(qualities.items(), start=1):\n",
    "    # Calculate the CDF\n",
    "    values_sorted = np.sort(values)\n",
    "    cdf = np.arange(1, len(values) + 1) / len(values)\n",
    "\n",
    "    # Add a trace for each type to its respective subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=values_sorted,\n",
    "            y=cdf,\n",
    "            mode=\"lines\",\n",
    "            name=(\"- \" if key in [\"psnr\", \"ssim\", \"nmi\", \"artifacts\"] else \"\")\n",
    "            + QUALITY_METRICS[key],\n",
    "        ),\n",
    "        row=1,\n",
    "        col=i,\n",
    "    )\n",
    "\n",
    "    # Update x-axis title for each subplot\n",
    "    fig.update_xaxes(\n",
    "        title_text=(\"- \" if key in [\"psnr\", \"ssim\", \"nmi\", \"artifacts\"] else \"\")\n",
    "        + QUALITY_METRICS[key],\n",
    "        row=1,\n",
    "        col=i,\n",
    "    )\n",
    "\n",
    "    # Find intersection points with horizontal lines at a and b\n",
    "    intersect_a = np.interp(quality_threshold_low, cdf, values_sorted)\n",
    "    intersect_b = np.interp(quality_threshold_high, cdf, values_sorted)\n",
    "\n",
    "    # Add dashed lines for intersection points\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[intersect_a, intersect_a],\n",
    "            y=[0, quality_threshold_low],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"red\", dash=\"dash\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=i,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[intersect_b, intersect_b],\n",
    "            y=[0, quality_threshold_high],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"blue\", dash=\"dash\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=i,\n",
    "    )\n",
    "\n",
    "# Add horizontal lines at a*100% and b*100%\n",
    "fig.add_hline(\n",
    "    y=quality_threshold_low,\n",
    "    line_dash=\"dot\",\n",
    "    annotation_text=f\"{quality_threshold_low*100}%\",\n",
    "    annotation_position=\"bottom right\",\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=quality_threshold_high,\n",
    "    line_dash=\"dot\",\n",
    "    annotation_text=f\"{quality_threshold_high*100}%\",\n",
    "    annotation_position=\"top right\",\n",
    ")\n",
    "\n",
    "\n",
    "# Update layout of the figure\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Distribution Function Plot with Independent X-Axes\",\n",
    "    yaxis_title=\"Cumulative Probability\",\n",
    "    yaxis=dict(tickformat=\".0%\", range=[0, 1]),  # Setting y-axis as percentage\n",
    ")\n",
    "\n",
    "ranges = {}\n",
    "\n",
    "# Loop through each item in the dictionary and add annotations for intersections\n",
    "for i, (key, values) in enumerate(qualities.items(), start=1):\n",
    "    # Calculate the CDF\n",
    "    values_sorted = np.sort(values)\n",
    "    cdf = np.arange(1, len(values) + 1) / len(values)\n",
    "\n",
    "    # Find intersection points with horizontal lines at a and b\n",
    "    intersect_a = np.interp(quality_threshold_low, cdf, values_sorted)\n",
    "    intersect_b = np.interp(quality_threshold_high, cdf, values_sorted)\n",
    "\n",
    "    # Add annotations for intersection points\n",
    "    fig.add_annotation(\n",
    "        x=intersect_a,\n",
    "        y=0.05,\n",
    "        xref=f\"x{i}\",\n",
    "        yref=\"y\",\n",
    "        text=f\"<b>{intersect_a:.2f}</b>\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"red\", size=12),\n",
    "        xshift=-10 if i > 1 else 10,  # Adjust position to avoid overlap\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=intersect_b,\n",
    "        y=0,\n",
    "        xref=f\"x{i}\",\n",
    "        yref=\"y\",\n",
    "        text=f\"<b>{intersect_b:.2f}</b>\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"blue\", size=12),\n",
    "        xshift=-10 if i > 1 else 10,  # Adjust position to avoid overlap\n",
    "    )\n",
    "    ranges[key] = (\n",
    "        (intersect_a, intersect_b)\n",
    "        if key not in [\"psnr\", \"ssim\", \"nmi\", \"artifacts\"]\n",
    "        else (-intersect_a, -intersect_b)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_quality(qualities):\n",
    "    normed_qualties = {\n",
    "        key: [\n",
    "            (value - ranges[key][0])\n",
    "            / (ranges[key][1] - ranges[key][0])\n",
    "            * (quality_threshold_high - quality_threshold_low)\n",
    "            + quality_threshold_low\n",
    "            for value in qualities[key]\n",
    "        ]\n",
    "        for key in qualities.keys()\n",
    "    }\n",
    "    weight = {\n",
    "        \"legacy_fid\": 1 / 4 / 2,\n",
    "        \"clip_fid\": 1 / 4 / 2,\n",
    "        \"psnr\": 1 / 4 / 3,\n",
    "        \"ssim\": 1 / 4 / 3,\n",
    "        \"nmi\": 1 / 4 / 3,\n",
    "        \"lpips\": 1 / 4 / 1,\n",
    "        \"aesthetics\": 1 / 4 / 2,\n",
    "        \"artifacts\": 1 / 4 / 2,\n",
    "    }\n",
    "    return [\n",
    "        sum([weight[key] * normed_qualties[key][idx] for key in normed_qualties.keys()])\n",
    "        for idx in range(len(list(normed_qualties.values())[0]))\n",
    "    ]\n",
    "\n",
    "\n",
    "def modified_interp(x, xp, fp):\n",
    "    if x < min(xp):\n",
    "        return np.inf\n",
    "    elif x > max(xp):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.interp(x, xp, fp)\n",
    "\n",
    "\n",
    "def rank_with_ties(column, threshold=0.01):\n",
    "    # Dictionary to hold the ranks\n",
    "    rank_dict = {}\n",
    "    rank = 1\n",
    "\n",
    "    # Sort the unique values to assign ranks in order\n",
    "    for value in sorted(np.unique(column)):\n",
    "        if value not in rank_dict:\n",
    "            rank_dict[value] = rank\n",
    "            rank += 1\n",
    "\n",
    "    # Adjust ranks for values within the threshold\n",
    "    unique_values = sorted(rank_dict.keys())\n",
    "    for i in range(1, len(unique_values)):\n",
    "        if unique_values[i] - unique_values[i - 1] < threshold:\n",
    "            rank_dict[unique_values[i]] = rank_dict[unique_values[i - 1]]\n",
    "\n",
    "    # Map the ranks back to the original order of the column\n",
    "    ranks = [rank_dict[val] for val in column]\n",
    "\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def plot_aggregated_2d_plot(watermark_method):\n",
    "    df_sel = df.copy()\n",
    "    df_sel.drop(columns=[\"acc_100\"], inplace=True)\n",
    "    df_sel = df_sel[df_sel[\"eval_setup\"] == \"removal\"].dropna()\n",
    "    df_sel = df_sel[df_sel[\"source_name\"] == watermark_method]\n",
    "\n",
    "    qualities = {\n",
    "        k: [v[0] for v in df_sel[k] if v is not None]\n",
    "        for k in QUALITY_METRICS.keys()\n",
    "        if k not in [\"watson\", \"clip_score\"]\n",
    "    }\n",
    "    # df_sel[\"normalized_quality\"] = normalized_quality(qualities)\n",
    "    df_sel[\"normalized_quality\"] = [v[0] for v in df_sel[\"normalized_quality\"]]\n",
    "\n",
    "    df_sel = df_sel[\n",
    "        [\n",
    "            \"dataset_name\",\n",
    "            \"attack_name\",\n",
    "            \"attack_strength\",\n",
    "            performance_metric,\n",
    "            \"normalized_quality\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    colors = (\n",
    "        px.colors.qualitative.Plotly\n",
    "        + px.colors.qualitative.D3\n",
    "        + px.colors.qualitative.G10\n",
    "    )\n",
    "    show_text = False\n",
    "    line_width = 3\n",
    "    marker_size = 9\n",
    "    tick_size = 10\n",
    "    legend_fontsize = 15\n",
    "    plot_height = 800\n",
    "\n",
    "    fig = go.Figure()\n",
    "    leaderboard_row = []\n",
    "    for i, attack_name in enumerate(ATTACK_NAMES.keys()):\n",
    "        if attack_name in [\"4x_regen_bmshj\", \"4x_regen_kl_vae\"]:\n",
    "            continue\n",
    "        if attack_name.startswith(\"dist\"):\n",
    "            marker = \"square\"\n",
    "        elif attack_name.startswith(\"adv\"):\n",
    "            marker = \"star\"\n",
    "        else:\n",
    "            marker = \"x\"\n",
    "\n",
    "        df_cat = df_sel[df_sel[\"attack_name\"] == attack_name].drop(\n",
    "            columns=[\"attack_name\"]\n",
    "        )\n",
    "        df_cat = (\n",
    "            df_cat.groupby(\"attack_strength\")[\n",
    "                [performance_metric, \"normalized_quality\"]\n",
    "            ]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        df_cat = df_cat.assign(\n",
    "            attack_strength_float=df_cat[\"attack_strength\"].astype(float)\n",
    "        )\n",
    "        df_cat = df_cat.sort_values(\"attack_strength_float\").drop(\n",
    "            columns=[\"attack_strength_float\"]\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_cat[\"normalized_quality\"],\n",
    "                y=df_cat[performance_metric],\n",
    "                text=df_cat[\"attack_strength\"],\n",
    "                mode=\"lines+markers+text\" if show_text else \"lines+markers\",\n",
    "                name=ATTACK_NAMES[attack_name]\n",
    "                if attack_name in ATTACK_NAMES\n",
    "                else \"N/A\",\n",
    "                line=dict(color=colors[i % len(colors)], width=line_width),\n",
    "                marker=dict(symbol=marker, size=marker_size),\n",
    "                textposition=\"bottom right\",\n",
    "            )\n",
    "        )\n",
    "        performance_threshold_low_str = f\"Q@{performance_threshold_low:.2f}P\"\n",
    "        performance_threshold_high_str = f\"Q@{performance_threshold_high:.2f}P\"\n",
    "        leaderboard_row.append(\n",
    "            {\n",
    "                \"Attack\": ATTACK_NAMES[attack_name],\n",
    "                performance_threshold_high_str: modified_interp(\n",
    "                    performance_threshold_high,\n",
    "                    df_cat[performance_metric][::-1],\n",
    "                    df_cat[\"normalized_quality\"][::-1],\n",
    "                ),\n",
    "                performance_threshold_low_str: modified_interp(\n",
    "                    performance_threshold_low,\n",
    "                    df_cat[performance_metric][::-1],\n",
    "                    df_cat[\"normalized_quality\"][::-1],\n",
    "                ),\n",
    "                \"AvgP\": np.mean(df_cat[performance_metric]),\n",
    "                \"AvgQ\": np.mean(df_cat[\"normalized_quality\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    leaderboard_df = pd.DataFrame(leaderboard_row)\n",
    "    leaderboard_df[performance_threshold_high_str + \"_rank\"] = rank_with_ties(\n",
    "        leaderboard_df[performance_threshold_high_str]\n",
    "    )\n",
    "    leaderboard_df[performance_threshold_low_str + \"_rank\"] = rank_with_ties(\n",
    "        leaderboard_df[performance_threshold_low_str]\n",
    "    )\n",
    "    leaderboard_df[\"AvgP_rank\"] = rank_with_ties(leaderboard_df[\"AvgP\"])\n",
    "    leaderboard_df[\"AvgQ_rank\"] = rank_with_ties(leaderboard_df[\"AvgQ\"])\n",
    "    leaderboard_df_sorted = leaderboard_df.sort_values(\n",
    "        by=[\n",
    "            performance_threshold_high_str + \"_rank\",\n",
    "            performance_threshold_low_str + \"_rank\",\n",
    "            \"AvgP_rank\",\n",
    "            \"AvgQ_rank\",\n",
    "        ],\n",
    "        ascending=[True, True, True, True],\n",
    "    )\n",
    "    leaderboard_df_sorted[\"Rank\"] = (\n",
    "        leaderboard_df_sorted[\n",
    "            [\n",
    "                performance_threshold_high_str + \"_rank\",\n",
    "                performance_threshold_low_str + \"_rank\",\n",
    "                \"AvgP_rank\",\n",
    "                \"AvgQ_rank\",\n",
    "            ]\n",
    "        ]\n",
    "        .apply(tuple, axis=1)\n",
    "        .rank(method=\"min\")\n",
    "        .astype(int)\n",
    "    )\n",
    "    # leaderboard_df_sorted = leaderboard_df_sorted.drop(\n",
    "    #     columns=[\n",
    "    #         performance_threshold_high_str + \"_rank\",\n",
    "    #         performance_threshold_low_str + \"_rank\",\n",
    "    #         \"AvgP_rank\",\n",
    "    #         \"AvgQ_rank\",\n",
    "    #     ]\n",
    "    # )\n",
    "    leaderboard_df_sorted[\"Watermark\"] = WATERMARK_METHODS[watermark_method]\n",
    "    leaderboard_df_sorted = leaderboard_df_sorted[\n",
    "        [\"Watermark\", \"Attack\", \"Rank\"]\n",
    "        + [\n",
    "            col\n",
    "            for col in leaderboard_df_sorted.columns\n",
    "            if col not in [\"Watermark\", \"Attack\", \"Rank\"]\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1.6],\n",
    "            y=[performance_threshold_high, performance_threshold_high],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"black\", dash=\"dash\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0, 1.6],\n",
    "            y=[performance_threshold_low, performance_threshold_low],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"black\", dash=\"dash\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Adjust the layout for the line plot and add legend\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Comparison of Attacks on {WATERMARK_METHODS[watermark_method]}\",\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"left\",\n",
    "            x=1.05,\n",
    "            font=dict(size=legend_fontsize),\n",
    "        ),\n",
    "        xaxis=dict(title=\"Normalized Quality\", tickfont=dict(size=tick_size)),\n",
    "        yaxis=dict(\n",
    "            title=PERFORMANCE_METRICS[performance_metric], tickfont=dict(size=tick_size)\n",
    "        ),\n",
    "        height=plot_height,\n",
    "    )\n",
    "\n",
    "    return leaderboard_df_sorted, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboards = []\n",
    "fig_jsons = {}\n",
    "for watermark_method in WATERMARK_METHODS.keys():\n",
    "    leaderboard, fig = plot_aggregated_2d_plot(watermark_method)\n",
    "    # fig.show()\n",
    "    fig_jsons[watermark_method] = fig.to_json()\n",
    "    leaderboards.append(leaderboard)\n",
    "# leaderboard = pd.concat(leaderboards, axis=0)\n",
    "# display(HTML(leaderboard.to_html(index=False)))\n",
    "# leaderboard.to_csv(\"leaderboard.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "Checking for inconsistency in record types\n",
      "Missing diffusiondb, tree_ring, 2x_regen, 10.0, reverse\n",
      "Missing diffusiondb, tree_ring, adv_emb_clip_untg_alphaRatio_0.05_step_200, 2.0, decode\n",
      "Missing diffusiondb, tree_ring, 2x_regen, 10.0, decode\n",
      "Missing diffusiondb, tree_ring, 2x_regen, 10.0, metric\n",
      "Missing diffusiondb, stable_sig, 2x_regen, 10.0, metric\n",
      "Missing diffusiondb, stegastamp, 2x_regen, 10.0, decode\n",
      "Missing diffusiondb, stegastamp, 2x_regen, 10.0, metric\n",
      "Missing mscoco, tree_ring, 2x_regen, 10.0, status\n",
      "Missing dalle3, tree_ring, 2x_regen, 10.0, status\n",
      "############################################################\n",
      "Checking for inconsistency across datasetes and sources\n",
      "Missing diffusiondb, tree_ring, adv_emb_clip_untg_alphaRatio_0.05_step_200, 2.0\n",
      "Missing diffusiondb, tree_ring, 2x_regen, 10.0\n",
      "Missing diffusiondb, stable_sig, 2x_regen, 10.0\n",
      "Missing diffusiondb, stegastamp, 2x_regen, 10.0\n",
      "Missing mscoco, tree_ring, 2x_regen, 10.0\n",
      "Missing dalle3, tree_ring, 2x_regen, 10.0\n"
     ]
    }
   ],
   "source": [
    "from dev import *\n",
    "\n",
    "\n",
    "record_keys_per_dataset_source = {}\n",
    "print(\"#\" * 60)\n",
    "print(\"Checking for inconsistency in record types\")\n",
    "for dataset_name in DATASET_NAMES.keys():\n",
    "    for source_name in WATERMARK_METHODS.keys():\n",
    "        record_keys_per_result_type = {}\n",
    "        result_types_expected = (\n",
    "            [\"status\"]\n",
    "            + ([\"reverse\"] if source_name in [\"tree_ring\"] else [])\n",
    "            + [\"decode\", \"metric\"]\n",
    "        )\n",
    "        for result_type in result_types_expected:\n",
    "            record_keys_per_result_type[result_type] = set(\n",
    "                [\n",
    "                    (key[1], key[2])\n",
    "                    for key in get_all_json_paths(\n",
    "                        lambda _dataset_name, _attack_name, _attack_strength, _source_name, _result_type: (\n",
    "                            (_dataset_name == dataset_name)\n",
    "                            and (\n",
    "                                _source_name == source_name\n",
    "                                if source_name != \"real\"\n",
    "                                else _source_name.startswith(\"real\")\n",
    "                            )\n",
    "                            and (_result_type == result_type)\n",
    "                        )\n",
    "                    ).keys()\n",
    "                ]\n",
    "            )\n",
    "        for result_type in result_types_expected:\n",
    "            for attack_name, attack_strength in (\n",
    "                set.union(*record_keys_per_result_type.values())\n",
    "                - record_keys_per_result_type[result_type]\n",
    "            ):\n",
    "                print(\n",
    "                    f\"Missing {dataset_name}, {source_name}, {attack_name}, {attack_strength}, {result_type}\"\n",
    "                )\n",
    "        record_keys_per_dataset_source[(dataset_name, source_name)] = set.intersection(\n",
    "            *record_keys_per_result_type.values()\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"#\" * 60)\n",
    "print(\"Checking for inconsistency across datasetes and sources\")\n",
    "for dataset_name in DATASET_NAMES.keys():\n",
    "    for source_name in WATERMARK_METHODS.keys():\n",
    "        for attack_name, attack_strength in (\n",
    "            set.union(*record_keys_per_dataset_source.values())\n",
    "            - record_keys_per_dataset_source[(dataset_name, source_name)]\n",
    "        ):\n",
    "            print(\n",
    "                f\"Missing {dataset_name}, {source_name}, {attack_name}, {attack_strength}\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

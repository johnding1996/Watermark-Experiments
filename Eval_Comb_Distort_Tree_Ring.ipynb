{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Combined Natural Distortions for Attacking Tree-Ring Watermarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import wandb, os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Relative imports\n",
    "from metrics import *\n",
    "from tree_ring import *\n",
    "from guided_diffusion import *\n",
    "from distortions import *\n",
    "from utils import *\n",
    "\n",
    "# Experiment name\n",
    "experiment_name = \"Eval_Comb_Distort_Tree_Ring\"\n",
    "\n",
    "# Experiment parameters\n",
    "image_size = 64\n",
    "dataset_name = \"Tiny-ImageNet\"\n",
    "dataset_template = dataset_name\n",
    "num_sample_per_class = 20  # So that we can have 20*200 = 4000 images for Tiny-ImageNet\n",
    "\n",
    "\n",
    "tree_ring_paras = dict(\n",
    "    w_channel=2,\n",
    "    w_pattern=\"ring\",\n",
    "    w_mask_shape=\"circle\",\n",
    "    w_radius=10,\n",
    "    w_measurement=\"l1_complex\",\n",
    "    w_injection=\"complex\",\n",
    ")\n",
    "# Seeds\n",
    "sampling_seed = 0\n",
    "distortion_seed = 0\n",
    "\n",
    "# Wandb and device setup\n",
    "os.environ[\"WANDB_DIR\"] = f\"results/{experiment_name}/\"\n",
    "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "wandb.init(\n",
    "    project=experiment_name,\n",
    "    name=f\"\",\n",
    "    config={},\n",
    "    save_code=False,\n",
    ")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Image Quality Metrics for Tree-Ring Watermarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID scores between:\n",
      "  (original, wo/ watermark): ($430.5 \\pm 3.0$) $\\times 10^{-1}$\n",
      "  (original, w/ watermark): ($531.7 \\pm 3.4$) $\\times 10^{-1}$\n",
      "  (wo/ watermark, w/ watermark): ($376.6 \\pm 2.6$) $\\times 10^{-1}$\n"
     ]
    }
   ],
   "source": [
    "# Load the original imagenet subset\n",
    "dataset_org, class_names_org = load_imagenet_subset(\n",
    "    dataset_name, convert_to_tensor=False\n",
    ")\n",
    "\n",
    "# Load generated images without watermarks\n",
    "dataset_wo, class_names_wo = load_imagenet_guided(\n",
    "    image_size, dataset_template, convert_to_tensor=False\n",
    ")\n",
    "\n",
    "# Load generated images with watermarks\n",
    "dataset_w, class_names_w, keys, messages = load_tree_ring_guided(\n",
    "    image_size,\n",
    "    dataset_template,\n",
    "    num_key_seeds=1,\n",
    "    num_message_seeds=1,\n",
    "    convert_to_tensor=False,\n",
    ")\n",
    "\n",
    "# Sample the images, class evenly distributed\n",
    "assert class_names_org == class_names_wo == class_names_w\n",
    "images_org, labels_org = sample_images_by_label_set(\n",
    "    dataset_org, num_sample_per_class, sampling_seed=sampling_seed\n",
    ")\n",
    "images_wo, labels_wo = sample_images_by_label_set(\n",
    "    dataset_wo, num_sample_per_class, sampling_seed=sampling_seed\n",
    ")\n",
    "images_w, labels_w = sample_images_by_label_set(\n",
    "    dataset_w, num_sample_per_class, sampling_seed=sampling_seed\n",
    ")\n",
    "assert labels_org == labels_wo == [label[0] for label in labels_w]\n",
    "\n",
    "# Metrics to calculate\n",
    "metrics_funcs = dict(\n",
    "    FID=lambda images1, images2: compute_fid_repeated(\n",
    "        images1,\n",
    "        images2,\n",
    "        num_repeats=3,\n",
    "        sample_size=2048,\n",
    "        pairwise=True,\n",
    "        sampling_seed=sampling_seed,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Calculate and print results\n",
    "for metric_name, metric_func in metrics_funcs.items():\n",
    "    means, stds = tuples_to_lists(\n",
    "        [\n",
    "            metric_func(images_org, images_wo),\n",
    "            metric_func(images_org, images_w),\n",
    "            metric_func(images_wo, images_w),\n",
    "        ]\n",
    "    )\n",
    "    fmt_strings = format_mean_and_std_list(means, stds, style=\"latex\")\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"metric\": metric_name,\n",
    "            \"dist_org_wo\": means[0],\n",
    "            \"dist_org_w\": means[1],\n",
    "            \"dist_wo_w\": means[2],\n",
    "        }\n",
    "    )\n",
    "    print(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                f\"{metric_name} scores between:\",\n",
    "                f\"  (original, wo/ watermark): {fmt_strings[0]}\",\n",
    "                f\"  (original, w/ watermark): {fmt_strings[1]}\",\n",
    "                f\"  (wo/ watermark, w/ watermark): {fmt_strings[2]}\",\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
